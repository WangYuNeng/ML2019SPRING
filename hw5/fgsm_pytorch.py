# -*- coding: utf-8 -*-
"""FGSM_pytorch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wwIbmnoQrLTF-7LPoSPVpZ_jRMPU3VjM
"""

import numpy as np
#import matplotlib.pyplot as plt 
from PIL import Image
import torch
from torch.autograd import Variable
import torch.nn as nn 
import torch.nn.functional as F 
import torchvision 
import torch.optim as optim 
from torchvision import transforms
#from tqdm import *
import torchvision.models 
import os
import sys

torch.manual_seed(0)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False
np.random.seed(0)

def get_filename(f):
    if f < 10:
        return "00" + str(f) + ".png"
    elif f < 100:
        return "0" + str(f) + ".png"
    else:
        return str(f) + ".png"

def image_loader(image_name):
    """load image, returns tensor"""
    loader = transforms.Compose([transforms.ToTensor()])
    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    image = Image.open(image_name)
    #image = image.convert("RGB") # Auto remove the "alpha" channel from png image
    image = loader(image).float()
    image = normalize(image).float()
    image = image.unsqueeze(0)  #this is for VGG, may not be needed for ResNet
    return image

import csv

inverse_transform = transforms.Compose([
   transforms.Normalize(mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],
                        std=[1/0.229, 1/0.224, 1/0.225]),
   transforms.ToPILImage(),
])

# Pretrained VGG16 model
resnet50 = torchvision.models.resnet50(pretrained=True)
resnet50.eval() # disable dropout, batchnorm
SoftmaxWithXent = nn.CrossEntropyLoss()
print (".. loaded pre-trained resnet50")
fail = 0
indir = sys.argv[1]
outdir = sys.argv[2]

xs, y_trues, y_preds, noises, y_preds_adversarial = [], [], [], [], []

for file in range(200):
    
    imloc = os.path.join(indir, get_filename(file))
    x = Variable(image_loader(imloc), requires_grad=True)
    output = resnet50.forward(x)
    
    y = Variable(torch.LongTensor(np.array([output.data.numpy().argmax()])), requires_grad = False)
    loss = SoftmaxWithXent(output, y)
    loss.backward()

    # Add perturbation 
    epsilon = 4.5/255/0.485
    x_grad     = torch.sign(x.grad.data)
    adv_x   = x.data + epsilon*x_grad 

    # Check adversarilized output 
    y_pred_adversarial = np.argmax(resnet50.forward(Variable(adv_x)).data.numpy())
    y_true = np.argmax(output.data.numpy())
    if y_pred_adversarial == y_true:
      fail += 1
    adv_x[0][0] = torch.clamp(adv_x[0][0], -0.485/0.229, 0.515/0.229)
    adv_x[0][1] = torch.clamp(adv_x[0][1], -0.456/0.224, 0.544/0.224)
    adv_x[0][2] = torch.clamp(adv_x[0][2], -0.406/0.225, 0.594/0.225)
    output_image = inverse_transform(adv_x.detach().cpu().view(3,224,224))
    output_image.save(os.path.join(outdir, get_filename(file)))
    #save_img(adv_x.data.numpy(), get_filename(file))
    #print(imloc, y_true, y_pred_adversarial)

#print(fail/200)
